---
eleventyNavigation:
  key: Research
  order: 3
layout: simple.njk
stylesheets:
  - "/styles/pages/research.css"
title: Research
description: Cutting-edge AI research projects and academic contributions
---

# Research

Advanced research projects exploring the frontiers of AI, machine learning, and software engineering. These projects contribute to academic understanding and push the boundaries of what's possible with intelligent systems.

<!-- Research ScrambleBench -->
<div class="project-brochure" id="scramblebench-research">
  <div class="project-visual">
    <i data-lucide="shield-check" class="project-icon"></i>
    <div class="project-codename">ScrambleBench</div>
    <div class="project-status">Research Release</div>
  </div>
  <div class="project-content">
    <h2>Contamination-Resistant LLM Evaluation Toolkit</h2>
    <div class="project-pitch">
      <p><strong>The Problem:</strong> Training data contamination makes LLM evaluation meaningless. Models perform well on benchmarks they've seen during training, giving false confidence in capabilities. How do you test what a model truly understands versus what it memorized?</p>
      
      <p><strong>The Solution:</strong> A comprehensive benchmarking framework that creates truly novel test cases by transforming existing benchmarks through constructed languages and document transformations, ensuring models are evaluated on genuinely unseen content.</p>
      
      <div class="project-features">
        <div class="feature-item">
          <strong>Constructed Language Translation:</strong> Transform benchmarks into artificial languages that preserve logical structure while eliminating memorization advantages.
        </div>
        <div class="feature-item">
          <strong>Document Transformation:</strong> Advanced text transformations and long-context document restructuring that maintains semantic meaning while creating novel test cases.
        </div>
        <div class="feature-item">
          <strong>Multi-Model Evaluation:</strong> Test 100+ models through OpenRouter integration with comprehensive statistical analysis and rich visualizations.
        </div>
        <div class="feature-item">
          <strong>Research-Grade Toolkit:</strong> Complete CLI and Python API designed for researchers and AI practitioners conducting rigorous evaluation studies.
        </div>
      </div>
      
      <p class="project-tagline">Finally know what your models actually understand—not what they memorized.</p>
      
      <div class="project-cta">
        <a href="https://sibylline.dev/scramblebench/" target="_blank" rel="noopener noreferrer" class="btn-unified btn-primary btn-margin-right">
          <span class="btn-inner">
            Documentation
            <i data-lucide="book-open"></i>
          </span>
        </a>
        <a href="https://github.com/sibyllinesoft/scramblebench" target="_blank" rel="noopener noreferrer" class="btn-unified btn-primary">
          <span class="btn-inner">
            View on GitHub
            <i data-lucide="github"></i>
          </span>
        </a>
      </div>
    </div>
  </div>
</div>

<!-- Research Lethe -->
<div class="project-brochure" id="lethe-research">
  <div class="project-visual">
    <i data-lucide="database" class="project-icon"></i>
    <div class="project-codename">Lethe</div>
    <div class="project-status">NeurIPS 2025</div>
  </div>
  <div class="project-content">
    <h2>Infinite Context Through Intelligent Forgetting Research</h2>
    <div class="project-pitch">
      <p><strong>The Research Question:</strong> Can AI agents achieve infinite context by intelligently filtering irrelevant information and rewriting verbose histories into efficient representations? Current approaches either hit token limits or require manual context curation, creating productivity bottlenecks.</p>
      
      <p><strong>Our Approach:</strong> Lethe research explores novel hybrid retrieval architectures that combine intelligent filtering, efficient rewriting, and adaptive compression. Our system eliminates context management overhead by automatically determining relevance and optimizing message representation for unlimited agent memory.</p>
      
      <div class="project-features">
        <div class="feature-item">
          <strong>Intelligent Forgetting Framework:</strong> Systematic evaluation of relevance filtering algorithms that automatically identify and remove irrelevant messages while preserving essential context information.
        </div>
        <div class="feature-item">
          <strong>Efficient Rewriting Research:</strong> Novel compression techniques that transform verbose conversations into information-dense representations, reducing token usage while maintaining semantic fidelity.
        </div>
        <div class="feature-item">
          <strong>Zero-Overhead Context Management:</strong> Elimination of manual context curation through automated relevance assessment and dynamic history optimization for infinite agent memory.
        </div>
        <div class="feature-item">
          <strong>Production-Validated Results:</strong> Complete experimental framework demonstrating infinite context capabilities with sub-3s performance and rigorous evaluation of forgetting effectiveness.
        </div>
      </div>
      
      <p class="project-tagline">Research foundation for infinite agent context through intelligent forgetting and zero-overhead memory management.</p>
      
    </div>
  </div>
</div>

<!-- Research FastPath -->
<div class="project-brochure" id="fastpath-research">
  <div class="project-visual">
    <i data-lucide="zap" class="project-icon"></i>
    <div class="project-codename">FastPath</div>
    <div class="project-status">Publication Ready</div>
  </div>
  <div class="project-content">
    <h2>PageRank Centrality for Intelligent Repository Content Selection</h2>
    <div class="project-pitch">
      <p><strong>The Research Question:</strong> Can PageRank centrality algorithms optimize repository content selection for LLM consumption? Current approaches use naive concatenation or basic similarity metrics, failing to capture code dependency relationships and importance hierarchies.</p>
      
      <p><strong>Our Innovation:</strong> FastPath V3 introduces the first application of PageRank centrality to repository analysis, creating intelligent dependency graphs that identify critical code components. Our novel multi-fidelity approach achieves 27.8% improvement in QA accuracy with rigorous statistical validation.</p>
      
      <div class="project-features">
        <div class="feature-item">
          <strong>PageRank Code Centrality:</strong> Novel application of PageRank algorithms to code dependency graphs, identifying central components that maximize understanding per token with statistical significance (p<0.001).
        </div>
        <div class="feature-item">
          <strong>Multi-Fidelity Architecture:</strong> Adaptive budget allocation across semantic chunks, dependency relationships, and documentation with submodular optimization ensuring optimal information density.
        </div>
        <div class="feature-item">
          <strong>Empirical Validation Framework:</strong> Comprehensive evaluation against baselines (BM25, TF-IDF) with 27.8% improvement in QA accuracy and large effect size (Cohen's d=3.11) across diverse repositories.
        </div>
        <div class="feature-item">
          <strong>Production Research:</strong> Complete implementation with 4.7× speedup, 75% memory reduction, and reproducible benchmark framework designed for academic publication standards.
        </div>
      </div>
      
      <p class="project-tagline">Bridging graph theory and software engineering: the first PageRank approach to intelligent code selection.</p>
      
      <div class="project-cta">
        <a href="https://github.com/sibyllinesoft/scribe/blob/main/paper/draft.pdf" target="_blank" rel="noopener noreferrer" class="btn-unified btn-primary">
          <span class="btn-inner">
            Research Paper
            <i data-lucide="file-text"></i>
          </span>
        </a>
      </div>
    </div>
  </div>
</div>

<!-- Research Matrix -->
<div class="project-brochure" id="matrix-research">
  <div class="project-visual">
    <i data-lucide="grid-3x3" class="project-icon"></i>
    <div class="project-codename">Matrix</div>
    <div class="project-status">Active Research</div>
  </div>
  <div class="project-content">
    <h2>Parametric Repository Generator for AI Agent Benchmarking</h2>
    <div class="project-pitch">
      <p><strong>The Research Challenge:</strong> How do we systematically evaluate AI coding agents? Current benchmarks use static codebases that don't reflect the complexity and variability of real development environments. We need controlled, realistic testing environments.</p>
      
      <p><strong>Our Innovation:</strong> Matrix (Parametric Repo Generator) creates sophisticated research platforms for benchmarking AI coding agents through parametric codebase generation. It provides a "wind tunnel" for testing agents with controllable complexity parameters.</p>
      
      <div class="project-features">
        <div class="feature-item">
          <strong>Parametric Control:</strong> Generate codebases with precise control over complexity metrics including lines of code, dependency depth, and coupling complexity.
        </div>
        <div class="feature-item">
          <strong>Realistic Bug Injection:</strong> Systematic injection of off-by-one errors, API misuse patterns, and null handling issues that mirror real development challenges.
        </div>
        <div class="feature-item">
          <strong>Comprehensive Test Generation:</strong> Automated creation of unit tests, integration tests, and metamorphic testing suites for complete validation coverage.
        </div>
        <div class="feature-item">
          <strong>Agent Instrumentation:</strong> Advanced behavior tracing and instrumentation system for detailed analysis of agent performance and decision-making patterns.
        </div>
      </div>
      
      <p class="project-tagline">Creating the scientific foundation for rigorous AI coding agent evaluation.</p>
      
    </div>
  </div>
</div>

<!-- Research Modules -->
<div class="project-brochure" id="modules-research">
  <div class="project-visual">
    <i data-lucide="cpu" class="project-icon"></i>
    <div class="project-codename">BEM</div>
    <div class="project-status">Implementation Complete</div>
  </div>
  <div class="project-content">
    <h2>Bolt-on Expert Modules for Dynamic Neural Network Adaptation</h2>
    <div class="project-pitch">
      <p><strong>The Problem:</strong> Traditional parameter-efficient fine-tuning methods like LoRA are static and don't adapt to varying task complexity or context. Current approaches can't handle distribution shifts or provide dynamic specialization based on input characteristics.</p>
      
      <p><strong>Our Solution:</strong> BEM introduces dynamic neural architectures that enable context-dependent expert routing and retrieval-aware adaptation. Our system generates context-specific weight modifications that adapt to different tasks and contexts in real-time.</p>
      
      <div class="project-features">
        <div class="feature-item">
          <strong>Context-Aware Parameter Generation:</strong> Dynamic weight modification system that specializes computational pathways based on input characteristics and task requirements.
        </div>
        <div class="feature-item">
          <strong>Multi-Expert Routing System:</strong> Intelligent routing that selects appropriate expert modules based on context analysis and task complexity assessment.
        </div>
        <div class="feature-item">
          <strong>Cross-Modal Support:</strong> Unified architecture supporting text, vision, and multimodal tasks with consistent performance across domains.
        </div>
        <div class="feature-item">
          <strong>Robust Performance:</strong> 12-42% better accuracy than 6 major MoE-LoRA competitors, maintains performance across distribution shifts and adversarial inputs.
        </div>
      </div>
      
      <p class="project-tagline">Proven: Dynamic neural architectures achieve superior adaptation with cross-domain robustness.</p>
      
      <div class="project-cta">
        <a href="https://github.com/sibyllinesoft/BEM/" target="_blank" rel="noopener noreferrer" class="btn-unified btn-primary btn-margin-right">
          <span class="btn-inner">
            View on GitHub
            <i data-lucide="github"></i>
          </span>
        </a>
        <a href="https://github.com/sibyllinesoft/BEM/blob/master/archive/paper/paper.pdf" target="_blank" rel="noopener noreferrer" class="btn-unified btn-primary">
          <span class="btn-inner">
            Research Paper
            <i data-lucide="file-text"></i>
          </span>
        </a>
      </div>
    </div>
  </div>
</div>

<!-- Research Arachne -->
<div class="project-brochure" id="arachne-research">
  <div class="project-visual">
    <i data-lucide="spider" class="project-icon"></i>
    <div class="project-codename">Arachne</div>
    <div class="project-status">Production Ready</div>
  </div>
  <div class="project-content">
    <h2>Advanced JavaScript Deobfuscation Engine</h2>
    <div class="project-pitch">
      <p><strong>The Research Challenge:</strong> Modern JavaScript obfuscation uses sophisticated techniques that defeat pattern-matching approaches. Can formal methods and constraint solving crack the most advanced obfuscation schemes that protect malware and defeat traditional analysis tools?</p>
      
      <p><strong>Our Innovation:</strong> ArachneJS is the first JavaScript deobfuscator built on intermediate representation (IR) analysis, Z3 constraint solving, and bytecode lifting. It achieves 95% success rate on advanced obfuscation where competitors manage only 45-70%.</p>
      
      <div class="project-features">
        <div class="feature-item">
          <strong>IR-Based Analysis:</strong> Multi-pass optimization pipeline using formal program analysis with Control Flow Graphs (CFG) and Static Single Assignment (SSA) form—the only tool with true semantic understanding.
        </div>
        <div class="feature-item">
          <strong>Constraint Solving Integration:</strong> Z3 SMT solver integration for symbolic execution and mathematical obfuscation cracking—handles constraint-based hiding that defeats all other tools.
        </div>
        <div class="feature-item">
          <strong>Bytecode Lifting Capabilities:</strong> Advanced QuickJS and V8 bytecode analysis for VM-based obfuscation—the only tool that can analyze bytecode-level protection schemes.
        </div>
        <div class="feature-item">
          <strong>Formal Correctness Guarantees:</strong> Property-based testing and mathematical verification ensure semantic preservation—zero false positives with proven correctness.
        </div>
      </div>
      
      <p class="project-tagline">Beyond pattern matching: formal methods meet practical JavaScript deobfuscation for security research.</p>
      
      <div class="project-cta">
        <a href="https://github.com/sibyllinesoft/arachne" target="_blank" rel="noopener noreferrer" class="btn-unified btn-primary">
          <span class="btn-inner">
            View on GitHub
            <i data-lucide="github"></i>
          </span>
        </a>
      </div>
    </div>
  </div>
</div>

<!-- Research Logos -->
<div class="project-brochure" id="logos-research">
  <div class="project-visual">
    <i data-lucide="brain-circuit" class="project-icon"></i>
    <div class="project-codename">Logos</div>
    <div class="project-status">Research Implementation</div>
  </div>
  <div class="project-content">
    <h2>Bayesian LISP Symbolic Reasoner for Agent Systems</h2>
    <div class="project-pitch">
      <p><strong>The Research Question:</strong> Can AI agents reason more effectively through constrained symbolic expressions with built-in uncertainty quantification? Traditional neural approaches lack interpretability and struggle with logical consistency, while symbolic systems ignore uncertainty.</p>
      
      <p><strong>Our Approach:</strong> Logos implements a novel Bayesian POMDP system that combines grammar-constrained S-expression decoding with Value of Information scheduling. The system enforces mathematical rigor through Blackwell dominance validation while learning optimal epistemic action sequences through multi-game cognitive experiments.</p>
      
      <div class="project-features">
        <div class="feature-item">
          <strong>Language Reasoning Model (LRM):</strong> Grammar-constrained decoding ensures all generated reasoning follows valid S-expression syntax with typed uncertainty representation.
        </div>
        <div class="feature-item">
          <strong>Bayesian Budget Optimization:</strong> Multi-dimensional cost tracking (time, computation, economic) with Lagrangian optimization for resource-constrained reasoning.
        </div>
        <div class="feature-item">
          <strong>Blackwell Dominance Framework:</strong> Epistemic actions must provably improve posterior beliefs—zero tolerance for information-destroying operations with mathematical validation.
        </div>
        <div class="feature-item">
          <strong>Parametric Game Laboratory:</strong> Battleship, Crafting, GridWorld, LogicGrid, and Mastermind generators provide controlled environments for cognitive experiment design.
        </div>
      </div>
      
      <p class="project-tagline">Bridging symbolic reasoning and probabilistic inference for explainable agent intelligence with formal correctness guarantees.</p>
      
      <div class="project-cta">
        <a href="https://github.com/sibyllinesoft/logos" target="_blank" rel="noopener noreferrer" class="btn-unified btn-primary">
          <span class="btn-inner">
            View on GitHub
            <i data-lucide="github"></i>
          </span>
        </a>
      </div>
    </div>
  </div>
</div>

